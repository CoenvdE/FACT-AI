{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IW_naPEc_-SO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43c88838-2ab6-4cd7-b4af-5ae2152e50dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vw2bsOjuIA4X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "117d2dca-95b1-4099-d54c-e1d5ed8ea53c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-b8zb3lge\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-b8zb3lge\n",
            "  Resolved https://github.com/openai/CLIP.git to commit a1d071733d7111c9c014f024669f959182114e33\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy (from clip==1.0)\n",
            "  Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m863.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (4.66.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (0.16.0+cu121)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->clip==1.0) (0.2.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->clip==1.0) (2.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->clip==1.0) (1.3.0)\n",
            "Building wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369497 sha256=3265dfb5197ba1d4fbab615c17dee4ef882b9b1c09546ee2a6cf182f633d3abf\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-c5jovrcn/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\n",
            "Successfully built clip\n",
            "Installing collected packages: ftfy, clip\n",
            "Successfully installed clip-1.0 ftfy-6.1.3\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.16.1 dill-0.3.7 multiprocess-0.70.15\n",
            "Collecting captum\n",
            "  Downloading captum-0.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from captum) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from captum) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from captum) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from captum) (4.66.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->captum) (2.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->captum) (1.3.0)\n",
            "Installing collected packages: captum\n",
            "Successfully installed captum-0.7.0\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Collecting torchcam\n",
            "  Downloading torchcam-0.4.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m789.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchcam) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from torchcam) (1.23.5)\n",
            "Requirement already satisfied: Pillow!=9.2.0,>=8.4.0 in /usr/local/lib/python3.10/dist-packages (from torchcam) (9.4.0)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from torchcam) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (2.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.7.0->torchcam) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3.0.0,>=2.0.0->torchcam) (2.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<3.0.0,>=2.0.0->torchcam) (1.3.0)\n",
            "Installing collected packages: torchcam\n",
            "Successfully installed torchcam-0.4.0\n"
          ]
        }
      ],
      "source": [
        "# Installations (uncomment if needed)\n",
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "!pip install datasets\n",
        "!pip install captum\n",
        "!pip install tqdm\n",
        "!pip install torchcam\n",
        "\n",
        "# System and OS\n",
        "import os\n",
        "import os.path as osp\n",
        "from collections import OrderedDict\n",
        "\n",
        "# Basic Libraries\n",
        "import json\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "\n",
        "# PyTorch related\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "# CLIP and related libraries\n",
        "from clip import clip\n",
        "from clip.simple_tokenizer import SimpleTokenizer as _Tokenizer\n",
        "\n",
        "# Model and Data Processing\n",
        "from transformers import AlignTextModel, AlignProcessor, AlignModel\n",
        "from PIL import Image\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "from captum.attr import Saliency\n",
        "from captum.attr import visualization as viz\n",
        "\n",
        "# CAM methods\n",
        "from torchcam.methods import GradCAM\n",
        "from torchcam.utils import overlay_mask\n",
        "\n",
        "# Datasets\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCBUyJUPMWYT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c97589a6-1f8f-46e6-970e-eda0789728cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jX41uM2Y_064",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "2ad01ed186cc4fbaa93783b4ca1aa7ba",
            "dd04051cfaac4ab69658738abe283114",
            "71fec566696c4fd790f206f4d46c5a60",
            "c69a06f36c7e486a910c851d102fcdc4",
            "3ef1fbaa833d4a82ba5b0230b0d238c8",
            "92e3ccae64fd427fb52f395a767df597",
            "84a4e7fb595f455bae127455c28d909b",
            "0db8673776744254a9f19110bac83e7c",
            "86a031ad1366456e95fb5c6656b54a3d",
            "4c155b51e49c40ab9313138a34a6314b",
            "da354e528a8c475a83fbf1c967fb8632",
            "ab7d02a2ff124e6fa1b10720ace7272c",
            "c7938a373bfb4d3e8eaff8fd61c301f1",
            "3d0c3fc847794a6385dd0c3ba627122c",
            "222e1bf73ae74615b78bcddab75ce7bf",
            "44ee20fff4c9478c83c62e350b49df3e",
            "d8cb4d3aa6dd4ccf9c3e9a73940b4f4c",
            "702858311e114023ae3741c0f2e24c79",
            "5430d8a71534436b8b50d51d101018e6",
            "b36b713b0caf453eafbe011eb9f7d4d2",
            "8c46fa462bc64ff487d87bf393346acf",
            "d352fe7a7b604b5a8e8b23c83f16e907",
            "b5b3df02fea34814bc07d985b90f5927",
            "5a068c63109040beb8196a23a1b6179c",
            "468d9cd1b7b744d7972b9f277358fc2d",
            "476a7da0d8be489c89f7e76a6999cffc",
            "0b88c58fb3ac4a22a9cb78a2fa127fcf",
            "316389363eb84108a2c86a9d728182a0",
            "08dfa1903d0f43d69b9371b4eee546aa",
            "d9acf10b627b4d81a53aafcfa8be1c62",
            "d43b9048569644ee912653a99f40ea26",
            "408fc7fc77fa4a7d8e2dbcbffd317607",
            "d53a4276bde74da5a900e49f443eb8ee"
          ]
        },
        "outputId": "c3306f07-9f1e-4ea4-a895-4186013139a2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.72k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ad01ed186cc4fbaa93783b4ca1aa7ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/85.4k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab7d02a2ff124e6fa1b10720ace7272c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading extra modules:   0%|          | 0.00/46.4k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b5b3df02fea34814bc07d985b90f5927"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# LOAD DATALOADERS WITH TRANSFORMED IMAGES TODO FOR LATER\n",
        "\n",
        "\n",
        "#using the ImageNet Transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224), # Cropping a central square patch of the image\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  #TO-DO figure out impact & optimal values\n",
        "])\n",
        "\n",
        "access_token = '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'\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for item in batch:\n",
        "        image = item['image']\n",
        "        label = item['label']\n",
        "\n",
        "        # Convert to PIL Image if not already (assuming image is a NumPy array or a tensor)\n",
        "        if not isinstance(image, Image.Image):\n",
        "            image = to_pil_image(image)\n",
        "\n",
        "        # Ensure the image is in RGB format\n",
        "        if image.mode != 'RGB':\n",
        "            image = image.convert('RGB')\n",
        "\n",
        "        # Apply transformations\n",
        "        image = transform(image)\n",
        "\n",
        "        # Append the transformed image and label to the lists\n",
        "        images.append(image)\n",
        "        labels.append(label)\n",
        "\n",
        "    # Stack images into a single tensor and convert labels to tensor\n",
        "    images = torch.stack(images)\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "subset_size = 10000  # Adjust this based on your needs, 10.000 is almost too much\n",
        "subset_data = []\n",
        "imagenet_data = load_dataset(\"imagenet-1k\", split=\"train\", streaming = True, token=access_token, trust_remote_code=True)\n",
        "\n",
        "# Manually iterate through the dataset and take a subset\n",
        "for i, sample in enumerate(imagenet_data):\n",
        "    if i >= subset_size:\n",
        "        break\n",
        "    subset_data.append(sample)\n",
        "\n",
        "# creating a DataLoader from this subset\n",
        "dataloader = DataLoader(subset_data, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "# Get validation set\n",
        "subset_size = 1000  # Adjust this based on your needs, 10.000 is almost too much\n",
        "subset_data = []\n",
        "validation_data = load_dataset(\"imagenet-1k\", split=\"validation\", streaming = True, token=access_token, trust_remote_code=True)\n",
        "for i, sample in enumerate(validation_data):\n",
        "    if i >= subset_size:\n",
        "        break\n",
        "    subset_data.append(sample)\n",
        "validation_loader = DataLoader(subset_data, batch_size=24, shuffle=None, collate_fn=collate_fn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SArU2BJ3AHjH"
      },
      "outputs": [],
      "source": [
        "def get_ImageNet_ClassNames():\n",
        "    \"\"\"\n",
        "    Reads and returns a list of class names from the ImageNet dataset.\n",
        "\n",
        "    This function reads a JSON file containing mappings of ImageNet class indices\n",
        "    to their respective human-readable names and returns a list of these names.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of strings where each string is a class name from ImageNet.\n",
        "    \"\"\"\n",
        "    # Path to the JSON file containing ImageNet class index and names\n",
        "    text_file = '/content/drive/MyDrive/FACT LICO 13/imagenet_class_index.json'\n",
        "\n",
        "    # Open the JSON file and load its contents into a Python dictionary\n",
        "    with open(text_file, 'r', encoding='utf-8') as f:\n",
        "        class_index = json.load(f)\n",
        "\n",
        "    # Initialize an empty list to hold the class names\n",
        "    names = []\n",
        "\n",
        "    # Iterate over the dictionary and extract class names\n",
        "    for i in range(len(class_index)):\n",
        "        # Append the last element (class name) of each list in the dictionary to 'names'\n",
        "        name = class_index[str(i)].replace(\"_\", \" \")\n",
        "\n",
        "        names.append(name)\n",
        "\n",
        "    # Return the list of class names\n",
        "    return names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysw9xtyl3IHl"
      },
      "outputs": [],
      "source": [
        "def get_encoded_labels(labels, prompt):\n",
        "    \"\"\"\n",
        "    Get prompts that correspond with labels of given batch.\n",
        "    \"\"\"\n",
        "    labels = labels.to(torch.int64)\n",
        "    selected_encodings = prompt[labels]\n",
        "    return selected_encodings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7_ztLUw_4vw"
      },
      "outputs": [],
      "source": [
        "class ModifiedResNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Resnet50 model structure, with modification that it also returns the image features\n",
        "    before the fully connected layer. This is used for OT loss\n",
        "    \"\"\"\n",
        "    def __init__(self, original_model):\n",
        "        super(ModifiedResNet, self).__init__()\n",
        "\n",
        "        # add layers from the original model\n",
        "        for name, module in original_model.named_children():\n",
        "            setattr(self, name, module)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        features = x # [Batch_size, number of filters, feature_map_height, feature_map_width]\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        logits = self.fc(x)\n",
        "        return logits, features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLeoQ8FvMFku"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    \"\"\"\n",
        "    MLP to transform text_features to image features dimensions to use text encoder\n",
        "    with any image encoder\n",
        "    the temperature parameter is trained here and used for MM loss in the training loop\n",
        "    output_dim is the dimension of the image_feature output of the image encoder\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "        # Temperature as trainable param for mm loss\n",
        "        self.temp = nn.Parameter(torch.ones([]) * np.log(1 / 0.07)) # DAAN LETS CHECK VALUES, MAYBE TRESHOLD\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = nn.functional.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVLf2IYCT1dF"
      },
      "outputs": [],
      "source": [
        "class TextEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    A text encoder module that uses a transformer model from a CLIP architecture\n",
        "    to encode text prompts into feature embeddings.\n",
        "\n",
        "    Attributes:\n",
        "        transformer (nn.Module): The transformer module from the CLIP model.\n",
        "        positional_embedding (Tensor): The positional embeddings from the CLIP model.\n",
        "        ln_final (nn.Module): Layer normalization applied after the transformer.\n",
        "        text_projection (Tensor): Linear projection layer for final text features.\n",
        "        dtype (torch.dtype): Data type of the model, typically torch.FloatTensor.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, clip_model):\n",
        "        \"\"\"\n",
        "        Initializes the TextEncoder module using components from a given CLIP model.\n",
        "\n",
        "        Args:\n",
        "            clip_model (CLIP): A pre-trained CLIP model.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # Adjust the CLIP model to the appropriate data type (float)\n",
        "        clip_model = clip_model.type(torch.FloatTensor)\n",
        "\n",
        "        # Extract relevant parts from the CLIP model\n",
        "        self.transformer = clip_model.transformer\n",
        "        self.positional_embedding = clip_model.positional_embedding\n",
        "        self.ln_final = clip_model.ln_final\n",
        "        self.text_projection = clip_model.text_projection\n",
        "        self.dtype = clip_model.dtype\n",
        "\n",
        "    def forward(self, prompts, tokenized_prompts):\n",
        "        \"\"\"\n",
        "        Forward pass for encoding all text prompts.\n",
        "\n",
        "        Args:\n",
        "            prompts (Tensor): The context vectors for prompts of all classes.\n",
        "            tokenized_prompts (Tensor): Tokenized representation of the prompts of all classes.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: The encoded text features.\n",
        "        \"\"\"\n",
        "        # Add positional embeddings to prompts and adjust dimensions for transformer\n",
        "        x = prompts + self.positional_embedding.type(self.dtype)\n",
        "        x = x.permute(1, 0, 2)  # Reorder dimensions for transformer input. # (batch, length, dimension) -> (length, batch, dimension) for transformer\n",
        "\n",
        "        # Pass the input through the transformer\n",
        "        x = self.transformer(x)\n",
        "        x = x.permute(1, 0, 2)  # Reorder dimensions back to original.  # (batch, length, dimension) <- (length, batch, dimension) for transformer\n",
        "\n",
        "        # Apply layer normalization\n",
        "        x = self.ln_final(x).type(self.dtype)\n",
        "\n",
        "        # Extract features corresponding to the end-of-token (EOT) embedding\n",
        "        # and apply text projection to get final text feature embeddings\n",
        "        # EOT: embeddings of entire input sequence\n",
        "        # self.text_projection is a learned linear transformation\n",
        "        # maps the high-dimensional transformer output to a lower-dimensional space suitable for downstream tasks\n",
        "        # print(f'x{x.shape}')\n",
        "        x = x[torch.arange(x.shape[0]), tokenized_prompts.argmax(dim=-1)] @ self.text_projection\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7vCN4DfT1h8"
      },
      "outputs": [],
      "source": [
        "# COMMENT AND CHECK LATER\n",
        "\n",
        "class PromptLearner(nn.Module):\n",
        "    \"\"\"\n",
        "    A PyTorch module for learning prompt embeddings in the context of a CLIP model.\n",
        "\n",
        "    This module creates and learns context vectors (prompts) for each class in a given set of class names.\n",
        "    These prompts are used with a CLIP model to produce text embeddings that are aligned with image features.\n",
        "\n",
        "    Attributes:\n",
        "        ctx (nn.Parameter): Learnable context vectors for each class.\n",
        "        token_prefix (Tensor): Start-of-sequence token embeddings from CLIP.\n",
        "        token_suffix (Tensor): End-of-sequence and class token embeddings from CLIP.\n",
        "        n_cls (int): Number of classes.\n",
        "        n_ctx (int): Number of context tokens.\n",
        "        class_token_position (str): Position of the class token in the prompt (options: 'middle', 'end', 'front').\n",
        "    \"\"\"\n",
        "    def __init__(self, classnames, clip_model):\n",
        "        \"\"\"\n",
        "        Initializes the PromptLearner module with class names and a CLIP model.\n",
        "\n",
        "        Args:\n",
        "            classnames (list): A list of class names (strings).\n",
        "            clip_model (CLIP): The pre-trained CLIP model from which certain layers are used.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        n_cls = len(classnames)\n",
        "        n_ctx = 12\n",
        "        # DAAN: ctx_init = None, so we can never provide our initialization ??\n",
        "        ctx_init = None\n",
        "        dtype = clip_model.dtype\n",
        "        ctx_dim = clip_model.ln_final.weight.shape[0]\n",
        "        self.N = 1\n",
        "\n",
        "        if ctx_init:\n",
        "            # use given words to initialize context vectors\n",
        "            ctx_init = ctx_init.replace(\"_\", \" \")\n",
        "            n_ctx = len(ctx_init.split(\" \"))\n",
        "            prompt = clip.tokenize(ctx_init)\n",
        "            with torch.no_grad():\n",
        "                embedding = clip_model.token_embedding(prompt).type(dtype)\n",
        "            ctx_vectors = embedding[0, 1 : 1 + n_ctx, :]\n",
        "            prompt_prefix = ctx_init\n",
        "        else:\n",
        "            # random initialization, DAAN: not random, right? we initialize with X's\n",
        "            if True:\n",
        "                print(\"Initializing class-specific contexts\")\n",
        "                ctx_vectors = torch.empty(n_cls, n_ctx, ctx_dim, dtype=dtype)\n",
        "            else:\n",
        "                print(\"Initializing a generic context\")\n",
        "                ctx_vectors = torch.empty(self.N, n_ctx, ctx_dim, dtype=dtype)\n",
        "            nn.init.normal_(ctx_vectors, std=0.02)   # define the prompt to be trained\n",
        "            prompt_prefix = \" \".join([\"X\"] * n_ctx)\n",
        "\n",
        "        print(f'Initial context: \"{prompt_prefix}\"')\n",
        "        print(f\"Number of context words (tokens): {n_ctx}\")\n",
        "\n",
        "        self.ctx = nn.Parameter(ctx_vectors)  # to be optimized\n",
        "\n",
        "        classnames = [name.replace(\"_\", \" \") for name in classnames]\n",
        "        name_lens = [len(_tokenizer.encode(name)) for name in classnames]\n",
        "\n",
        "        # '.' as end of sentence token for representation of whole sentence\n",
        "        prompts = [prompt_prefix + \" \" + name + \".\" for name in classnames]\n",
        "\n",
        "        tokenized_prompts = torch.cat([clip.tokenize(p) for p in prompts]) # (10, 77)\n",
        "        tokenized_prompts = tokenized_prompts.repeat(self.N,1)\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "            embedding = clip_model.token_embedding(tokenized_prompts).type(dtype)\n",
        "        print('tokenized prompts:', embedding.shape, 'ctx: ', self.ctx.shape)\n",
        "\n",
        "        # These token vectors will be saved when in save_model(),\n",
        "        # but they should be ignored in load_model() as we want to use\n",
        "        # those computed using the current class names DAAN: huh??? So we don't use it??\n",
        "        self.register_buffer(\"token_prefix\", embedding[:, :1, :])  # SOS\n",
        "        self.register_buffer(\"token_suffix\", embedding[:, 1 + n_ctx :, :])  # CLS, EOS\n",
        "\n",
        "        self.n_cls = n_cls\n",
        "        self.n_ctx = n_ctx\n",
        "        self.tokenized_prompts = tokenized_prompts  # torch.Tensor\n",
        "        self.name_lens = name_lens\n",
        "        # DAAN (and COEN): Why do we define 'middle' here? DAAN: There is a cls_loc arg in the shuffle, would be nice in forward to experiment with\n",
        "        self.class_token_position = 'middle'\n",
        "\n",
        "    # DAAN: Why do we give the prefix and suffix here if we dont use them?\n",
        "    def _ctx_shuffle(self, prefix, suffix, ctx, cls_loc = 'end', shuffleCLS = False):\n",
        "        \"\"\"\n",
        "        Shuffles the context vectors.\n",
        "\n",
        "        Args:\n",
        "            prefix (Tensor): Prefix token embeddings.\n",
        "            suffix (Tensor): Suffix token embeddings.\n",
        "            ctx (Tensor): Context vectors to shuffle.\n",
        "            cls_loc (str): Position of the class token in the prompt.\n",
        "            shuffleCLS (bool): Whether to shuffle the class token positions.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Shuffled context vectors.\n",
        "        \"\"\"\n",
        "\n",
        "        # shuffle the ctx along 2nd dimension\n",
        "        rand_idx = torch.randperm(ctx.shape[1])\n",
        "        shuffled_ctx = ctx[:, rand_idx, :]\n",
        "        return shuffled_ctx\n",
        "\n",
        "\n",
        "    def forward(self):\n",
        "        \"\"\"\n",
        "        Forward pass of the PromptLearner to create prompts for each class.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: A batch of prompts, one for each class.\n",
        "        \"\"\"\n",
        "\n",
        "        ctx = self.ctx\n",
        "        if ctx.dim() == 3:\n",
        "            ctx = ctx.unsqueeze(0)\n",
        "\n",
        "        ctx = ctx.contiguous().view(self.N*self.n_cls,self.n_ctx,ctx.shape[3])\n",
        "\n",
        "        prefix = self.token_prefix\n",
        "        suffix = self.token_suffix\n",
        "\n",
        "        # DAAN: do different context vectors still become different (or does this make them all the same) ?\n",
        "        ctx = self._ctx_shuffle(prefix, suffix, ctx)\n",
        "\n",
        "        if self.class_token_position == \"end\":\n",
        "            prompts = torch.cat(\n",
        "                [\n",
        "                    prefix,  # (n_cls, 1, dim)\n",
        "                    ctx,     # (n_cls, n_ctx, dim)\n",
        "                    suffix,  # (n_cls, *, dim)\n",
        "                ],\n",
        "                dim=1,\n",
        "            )\n",
        "\n",
        "        elif self.class_token_position == \"middle\":\n",
        "            half_n_ctx = self.n_ctx // 2\n",
        "            prompts = []\n",
        "            for i in range(self.n_cls):\n",
        "                name_len = self.name_lens[i]\n",
        "                prefix_i = prefix[i : i + 1, :, :]\n",
        "                class_i = suffix[i : i + 1, :name_len, :]\n",
        "                suffix_i = suffix[i : i + 1, name_len:, :]\n",
        "                ctx_i_half1 = ctx[i : i + 1, :half_n_ctx, :]\n",
        "                ctx_i_half2 = ctx[i : i + 1, half_n_ctx:, :]\n",
        "                prompt = torch.cat(\n",
        "                    [\n",
        "                        prefix_i,     # (1, 1, dim)\n",
        "                        ctx_i_half1,  # (1, n_ctx//2, dim)\n",
        "                        class_i,      # (1, name_len, dim)\n",
        "                        ctx_i_half2,  # (1, n_ctx//2, dim)\n",
        "                        suffix_i,     # (1, *, dim)\n",
        "                    ],\n",
        "                    dim=1,\n",
        "                )\n",
        "                prompts.append(prompt)\n",
        "            prompts = torch.cat(prompts, dim=0)\n",
        "\n",
        "        elif self.class_token_position == \"front\":\n",
        "            prompts = []\n",
        "            for i in range(self.n_cls):\n",
        "                name_len = self.name_lens[i]\n",
        "                prefix_i = prefix[i : i + 1, :, :]\n",
        "                class_i = suffix[i : i + 1, :name_len, :]\n",
        "                suffix_i = suffix[i : i + 1, name_len:, :]\n",
        "                ctx_i = ctx[i : i + 1, :, :]\n",
        "                prompt = torch.cat(\n",
        "                    [\n",
        "                        prefix_i,  # (1, 1, dim)\n",
        "                        class_i,   # (1, name_len, dim)\n",
        "                        ctx_i,     # (1, n_ctx, dim)\n",
        "                        suffix_i,  # (1, *, dim)\n",
        "                    ],\n",
        "                    dim=1,\n",
        "                )\n",
        "                prompts.append(prompt)\n",
        "            prompts = torch.cat(prompts, dim=0)\n",
        "\n",
        "        else:\n",
        "            raise ValueError\n",
        "        return prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQFA5ysw4Kjc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9316d5d-fe21-44ab-f848-2a6761b2c20b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████| 338M/338M [00:02<00:00, 152MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 512])\n"
          ]
        }
      ],
      "source": [
        "class_names = get_ImageNet_ClassNames()\n",
        "\n",
        "# Load CLIP model\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "\n",
        "\n",
        "# Tokenize and encode class names\n",
        "text_inputs = clip.tokenize(class_names).to(device)\n",
        "with torch.no_grad():\n",
        "    text_features_alt = model.encode_text(text_inputs).float()\n",
        "\n",
        "print(text_features_alt.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3at-qimtenr"
      },
      "outputs": [],
      "source": [
        "# CALCULATIONS FOR OT LOSS\n",
        "# DAAN can we get sinkhorn loss with a library? Would make the code much simpler\n",
        "\n",
        "\n",
        "# Adapted from https://github.com/gpeyre/SinkhornAutoDiff\n",
        "class SinkhornDistance(nn.Module):\n",
        "    \"\"\"\n",
        "    Given two empirical measures each with :math:`P_1` locations\n",
        "    :math:`x\\in\\mathbb{R}^{D_1}` and :math:`P_2` locations :math:`y\\in\\mathbb{R}^{D_2}`,\n",
        "    outputs an approximation of the regularized OT cost for point clouds.\n",
        "    Args:\n",
        "        eps (float): regularization coefficient\n",
        "        max_iter (int): maximum number of Sinkhorn iterations\n",
        "        reduction (string, optional): Specifies the reduction to apply to the output:\n",
        "            'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n",
        "            'mean': the sum of the output will be divided by the number of\n",
        "            elements in the output, 'sum': the output will be summed. Default: 'none'\n",
        "    Shape:\n",
        "        - Input: :math:`(N, P_1, D_1)`, :math:`(N, P_2, D_2)`\n",
        "        - Output: :math:`(N)` or :math:`()`, depending on `reduction`\n",
        "    \"\"\"\n",
        "    def __init__(self, eps, max_iter, reduction='none'):\n",
        "        super(SinkhornDistance, self).__init__()\n",
        "        self.eps = eps\n",
        "        self.max_iter = max_iter\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        # The Sinkhorn algorithm takes as input three variables :\n",
        "        C = self._cost_matrix(x, y)  # Wasserstein cost function\n",
        "        # print(x.size(), y.size(), C.shape)\n",
        "        x_points = x.shape[-2]\n",
        "        y_points = y.shape[-2]\n",
        "        # print(x.dim(), x_points, y_points)\n",
        "        if x.dim() == 2:\n",
        "            batch_size = 1\n",
        "        else:\n",
        "            batch_size = x.shape[0]\n",
        "\n",
        "        # both marginals are fixed with equal weights\n",
        "        mu = torch.empty(batch_size, x_points, dtype=torch.float,\n",
        "                         requires_grad=False).fill_(1.0 / x_points).squeeze().cuda()\n",
        "        nu = torch.empty(batch_size, y_points, dtype=torch.float,\n",
        "                         requires_grad=False).fill_(1.0 / y_points).squeeze().cuda()\n",
        "\n",
        "        u = torch.zeros_like(mu).cuda()\n",
        "        v = torch.zeros_like(nu).cuda()\n",
        "        # To check if algorithm terminates because of threshold\n",
        "        # or max iterations reached\n",
        "        actual_nits = 0\n",
        "        # Stopping criterion\n",
        "        thresh = 1e-3\n",
        "\n",
        "        # Sinkhorn iterations\n",
        "        for i in range(self.max_iter):\n",
        "            u1 = u  # useful to check the update\n",
        "            u = self.eps * (torch.log(mu+1e-8) - torch.logsumexp(self.M(C, u, v), dim=-1)) + u\n",
        "            v = self.eps * (torch.log(nu+1e-8) - torch.logsumexp(self.M(C, u, v).transpose(-2, -1), dim=-1)) + v\n",
        "            err = (u - u1).abs().sum(-1).mean()\n",
        "\n",
        "            actual_nits += 1\n",
        "            # print(i, err.item(), thresh)\n",
        "            if err.item() < thresh:\n",
        "                break\n",
        "\n",
        "        U, V = u, v\n",
        "        # Transport plan pi = diag(a)*K*diag(b)\n",
        "        pi = torch.exp(self.M(C, U, V))\n",
        "\n",
        "        # Sinkhorn distance\n",
        "        cost = torch.sum(pi * C, dim=(-2, -1)).mean()\n",
        "\n",
        "        # if self.reduction == 'mean':\n",
        "        #     cost = cost.mean()\n",
        "        # elif self.reduction == 'sum':\n",
        "        #     cost = cost.sum()\n",
        "\n",
        "        return cost\n",
        "\n",
        "    def M(self, C, u, v):\n",
        "        \"Modified cost for logarithmic updates\"\n",
        "        \"$M_{ij} = (-c_{ij} + u_i + v_j) / \\epsilon$\"\n",
        "        return (-C + u.unsqueeze(-1) + v.unsqueeze(-2)) / self.eps\n",
        "\n",
        "    @staticmethod\n",
        "    def _cost_matrix(x, y, p=2):\n",
        "        \"Returns the matrix of $|x_i-y_j|^p$.\"\n",
        "        # print(x.shape, y.shape)\n",
        "        x_col = x.unsqueeze(-2)\n",
        "        y_lin = y.unsqueeze(-3)\n",
        "        # print(x_col.shape, y_lin.shape)\n",
        "        C = torch.sum((torch.abs(x_col - y_lin)) ** p, -1)\n",
        "        # C.detach()\n",
        "        return C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXW4yyHnAdw-"
      },
      "outputs": [],
      "source": [
        "# MAKE FUNCTION OF IT\n",
        "def calculate_adjacency_matrix(features, temperature):\n",
        "    \"\"\"\n",
        "    calculates the adjacency matrix of the given features.\n",
        "    1. Calculate the pairwise Euclidean distances of the features\n",
        "    2. Apply the temperature scaling\n",
        "    \"\"\"\n",
        "    dist_matrix = torch.cdist(features, features, p=2)\n",
        "    adj_matrix = F.softmax(-dist_matrix / temperature, dim=1)\n",
        "    return adj_matrix\n",
        "\n",
        "\n",
        "def manifold_matching_loss(image_features, text_features, temperature):\n",
        "    \"\"\"\n",
        "    calculate the mm loss of the lico model\n",
        "    \"\"\"\n",
        "    A_F = calculate_adjacency_matrix(image_features, temperature)\n",
        "    A_G = calculate_adjacency_matrix(text_features, temperature)\n",
        "    # print(A_F.shape)\n",
        "    # Calculate the KL divergence loss for manifold matching\n",
        "    loss = F.kl_div(A_G.log(), A_F, reduction='batchmean')\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06l0U8vthab7"
      },
      "outputs": [],
      "source": [
        "def train_model(modified_resnet, dataloader, manifold_matching_loss, sinkhorn_loss, text2img_dim_transform, num_epochs, device, all_prompt_features, validation_loader, get_encoded_labels, ablation1, ablation2):\n",
        "    \"\"\"\n",
        "    Train the model.\n",
        "    \"\"\"\n",
        "\n",
        "    # Check validation before training\n",
        "    validate_model(modified_resnet, validation_loader, device)\n",
        "\n",
        "    # initialize the optimizer\n",
        "    optimizer = optim.SGD([\n",
        "        {'params': modified_resnet.parameters()},\n",
        "        {'params': text2img_dim_transform.parameters()},\n",
        "    ], lr=0.03, momentum=0.9, weight_decay=0.0001)\n",
        "\n",
        "    # Initialize the learning rate scheduler\n",
        "    scheduler = CosineAnnealingLR(optimizer, num_epochs)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        modified_resnet.train()\n",
        "        text2img_dim_transform.train()\n",
        "\n",
        "\n",
        "        if (epoch+1) % 2 == 1: # Change this to show which epoch we are\n",
        "            print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "        for images, labels in tqdm(dataloader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass through models\n",
        "            encoded_labels = get_encoded_labels(labels, all_prompt_features)\n",
        "            predictions, features_resnet = modified_resnet(images)\n",
        "\n",
        "            # feature_maps for OT loss\n",
        "            feature_maps = features_resnet.view(features_resnet.shape[0], features_resnet.shape[1], -1)\n",
        "            feature_maps = F.normalize(feature_maps, dim = 2)\n",
        "\n",
        "            # image_features for manifold loss\n",
        "            image_features = F.adaptive_avg_pool2d(features_resnet, 1)\n",
        "            image_features = image_features.view(images.shape[0], -1)\n",
        "            image_features = F.normalize(image_features, dim = -1)\n",
        "\n",
        "            # transform text_features dimension to match thos of the image encoder's output\n",
        "            text_features = text2img_dim_transform(encoded_labels)\n",
        "            text_features = F.normalize(text_features, dim = -1)\n",
        "\n",
        "            # get temperature parameter\n",
        "            temperature = text2img_dim_transform.temp\n",
        "\n",
        "            # calculate losses\n",
        "            CE_loss = torch.nn.functional.cross_entropy(predictions, labels)\n",
        "            MM_loss = manifold_matching_loss(image_features, text_features, temperature)\n",
        "            OT_loss = sinkhorn_loss(feature_maps, text_features)\n",
        "\n",
        "            if ablation1 == 'mm' or ablation2 == 'mm':\n",
        "                MM_loss = 0\n",
        "            if ablation1 == 'ot' or ablation2 == 'ot':\n",
        "                OT_loss = 0\n",
        "\n",
        "            # params according to the paper\n",
        "            alpha = 10\n",
        "            beta = 1\n",
        "\n",
        "            # Combine the losses or use them as needed\n",
        "            total_loss = CE_loss + alpha * MM_loss + beta * OT_loss\n",
        "\n",
        "            # Backward and optimize\n",
        "            optimizer.zero_grad()\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Clipping the parameter value to be within a min_val and max_val #CHOSEN BY OURSELVES\n",
        "            with torch.no_grad():  # This makes sure the operation is not tracked by autograd\n",
        "                text2img_dim_transform.temp.clamp_(min=0.1, max=3)\n",
        "\n",
        "\n",
        "        print(f\"temperature after last batch of epoch was:{temperature.item()}\")\n",
        "\n",
        "        # Evaluate on validation set or perform any other actions at the end of each epoch\n",
        "        validate_model(modified_resnet, validation_loader, device)\n",
        "        scheduler.step()\n",
        "\n",
        "        print(f\"Loss of last epoch in batch is: CE: {CE_loss}, OT: {OT_loss}, MM: {MM_loss}\")\n",
        "\n",
        "        # Save the model after training\n",
        "        torch.save(modified_resnet.state_dict(), f'/content/drive/MyDrive/FACT LICO 13/Models/modified_resnet_{ablation1}{ablation2}_{epoch}.pth') # CHANGE PATH ALWAYS\n",
        "        torch.save(text2img_dim_transform.state_dict(), f'/content/drive/MyDrive/FACT LICO 13/Models/text2img_dim_transform_{ablation1}{ablation2}_{epoch}.pth') # CHANGE PATH ALWAYS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a11pP4N22eEG"
      },
      "outputs": [],
      "source": [
        "def validate_model(modified_resnet, dataloader, device):\n",
        "    \"\"\"\n",
        "    Validate the model.\n",
        "    \"\"\"\n",
        "\n",
        "    modified_resnet.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    # Initialize variables to track metrics\n",
        "    total_accuracy = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    with torch.no_grad():  # No need to track gradients during validation\n",
        "        for images, labels in tqdm(dataloader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass through models\n",
        "            predictions, _ = modified_resnet(images)\n",
        "\n",
        "            # Calculate accuracy\n",
        "            _, predicted = torch.max(predictions.data, 1)\n",
        "            total_accuracy += (predicted == labels).sum().item()\n",
        "            num_batches += 1\n",
        "\n",
        "    # Compute average losses and accuracy\n",
        "    avg_accuracy = total_accuracy / (num_batches * dataloader.batch_size)\n",
        "\n",
        "    print(f'Validation results: Accuracy: {avg_accuracy}')\n",
        "\n",
        "    # Return to training mode\n",
        "    modified_resnet.train()\n",
        "    return avg_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDe0ypKnzBuA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38831196-e5e9-4312-9cfc-1e3fcb48189b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "clip_model, _ = clip.load(\"ViT-B/32\", device)\n",
        "classnames = get_ImageNet_ClassNames()\n",
        "_tokenizer = _Tokenizer()\n",
        "\n",
        "# 1. For pronmptleaner\n",
        "text_encoder = TextEncoder(clip_model).to(device)\n",
        "prompt_learner = PromptLearner(classnames, clip_model).to(device)\n",
        "total_prompt_from_labels = prompt_learner()\n",
        "tokenized_total_prompt = prompt_learner.tokenized_prompts.to(device)\n",
        "with torch.no_grad():\n",
        "    all_prompt_features = text_encoder(total_prompt_from_labels, tokenized_total_prompt)\n",
        "\n",
        "# For without Promptlearner\n",
        "# all_prompt_features = text_features_alt\n",
        "\n",
        "all_prompt_features = all_prompt_features.to(device)\n",
        "\n",
        "# create the resnet model\n",
        "resnet = models.resnet50(pretrained=False)\n",
        "resnet = resnet.to(device)\n",
        "modified_resnet = ModifiedResNet(resnet)\n",
        "modified_resnet = modified_resnet.to(device)\n",
        "\n",
        "\n",
        "# SAVE UNTRAINED MODEL FOR LATER COMPARISON\n",
        "pre_training_weights = copy.deepcopy(modified_resnet.state_dict())\n",
        "\n",
        "# create mlp\n",
        "input_dim = 512 # text encoder CLIP\n",
        "output_dim = 49 # to match 7x7 dimension of the feature maps\n",
        "hidden_dim = 512 # COEN: chat said the notation is hidden dim, output dim, so hidden dim = 512\n",
        "text2img_dim_transform = MLP(input_dim, hidden_dim, output_dim)\n",
        "text2img_dim_transform = text2img_dim_transform.to(device)\n",
        "\n",
        "\n",
        "# Initialize SinkhornDistance module\n",
        "sinkhorn_loss = SinkhornDistance(eps=0.1, max_iter=100, reduction='mean').to(device)\n",
        "\n",
        "# train model\n",
        "num_epochs = 90 # CHANGE THIS\n",
        "ablation1 = \"none\"\n",
        "ablation2 = \"none\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOmlbD0TILKj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563,
          "referenced_widgets": [
            "6002664ed8e64a4b86fed611b033e907",
            "5d1d2dae7b48453ead005fcb306bae7a",
            "c2c1f306fe28498a87fa7e48be8e7434",
            "4c97ab17e3db4a6ba7b17e9d9a6e57a8",
            "a440fcaba5ae4ba7afc8fb93f0eb9d9a",
            "e9ad82f96b0c491e8c5f4d103b7dc110",
            "300b45f5b947416d8559e6c1900c5878",
            "e7e86d83d0a44ce39b9ec92d6eb45559",
            "c3d53a7ea393427db92e08b42ccc21db",
            "4e0143fe6f8a4cd0ba46281c64e3b5ef",
            "b56d48aba49b4c5c8885f33cf1b6616a",
            "dd6a936f455446f18cbe2926652b8ba0",
            "c1b2c652a1cd4c75bf5b061b09e0eb59",
            "62495dffef8c46ba9c4f4b4b80d31458",
            "4526f6df79fe469a8718958bd72c1ef1",
            "e2a86ae4fde9453dbee600c36e961f38",
            "5d341a7319eb466794e61bd77d0f75c9",
            "88eec725c61d46b4967cd74f21f1e28c",
            "356bf7cc18594cc4a34fc15fbcd0184e",
            "ffa8dd72f0414ef2a3eac5c1c9c8f2d9",
            "5a4a891edd0f43759dbca48297fa8a2b",
            "ec826a48f39d406abc0f426631203de9",
            "c299a53508bd4c9abdc5951b5f763a82",
            "0e53743c092c40e59c65630a25f6c643",
            "ee98613527e54752925e632daf2d74c8",
            "b1bd568bd470403fa588cbfdc586c85f",
            "864ed169b90f42be8adcae5c15de85b6",
            "a86a4661fa8f4bd8b90de0d37529fa04",
            "4bce7da4069e4ddd97f128162f417c9a",
            "ce2e66cb53a94658bf2edc21beee0104",
            "a535e41bb9ed4914bebff6b3070dcf5b",
            "6ee673d300e34c75820cd9f87e72c52c",
            "76e47bacf3a4424ca20404ace441dc85",
            "d10e29182e554d6b9e15650f6a4a3d28",
            "6fcf8f55478b469cb1dc8cb044531ac1",
            "cd695ce38f3e455b81473dc1c752397b",
            "4c10646d9d8a44bda418c591eed6cbce",
            "5846d4a3bc194fc299cdb240597d49b5",
            "b83cd386524f45258e193dbf7d781e58",
            "81937a9cf50d40e28b8e3c9d186fec10",
            "cec563f423134f4e95d6da1f138acee1",
            "1c64c90bc2cb4101b23a95581f5b8adc",
            "bc16663948ca445fb01f400f168b4ada",
            "4aca5460752249e69a73a3e575a463e0"
          ]
        },
        "outputId": "98851a86-fe56-4a27-acee-e07ccb46c1b5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6002664ed8e64a4b86fed611b033e907"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation results: Accuracy: 0.0009765625\n",
            "Epoch 1/90\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd6a936f455446f18cbe2926652b8ba0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "temperature after last batch of epoch was:2.7385759353637695\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c299a53508bd4c9abdc5951b5f763a82"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation results: Accuracy: 0.001953125\n",
            "Loss of last epoch in batch is: CE: 8.309207916259766, OT: 0.20374803245067596, MM: 0.003949718549847603\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d10e29182e554d6b9e15650f6a4a3d28"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-9ba96ce9b069>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodified_resnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmanifold_matching_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msinkhorn_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext2img_dim_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_prompt_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_encoded_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mablation1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mablation2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-ed25f8049c1c>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(modified_resnet, dataloader, manifold_matching_loss, sinkhorn_loss, text2img_dim_transform, num_epochs, device, all_prompt_features, validation_loader, get_encoded_labels, ablation1, ablation2)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# Backward and optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_model(modified_resnet, dataloader, manifold_matching_loss, sinkhorn_loss, text2img_dim_transform, num_epochs, device, all_prompt_features, validation_loader, get_encoded_labels, ablation1, ablation2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcU_LNOfHiBj"
      },
      "source": [
        "QUICK CHECK TO SEE IF MODEL WEIGHTS TRANSFER AND IF RESULTS CAN BE VISUALIZED with original pretrained weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnqdEQp1dEwB"
      },
      "outputs": [],
      "source": [
        "# from torchvision.models import resnet50\n",
        "# from torchcam.methods import GradCAM\n",
        "# from torchcam.utils import overlay_mask\n",
        "# import torch\n",
        "# from torchvision.transforms.functional import to_pil_image\n",
        "# import torchvision.models as models\n",
        "\n",
        "# Load weights of modified resnet into resnet50\n",
        "resnet50_for_gradcam = models.resnet50(pretrained=False).to(device)\n",
        "resnet50_for_gradcam.load_state_dict(pre_training_weights)\n",
        "\n",
        "# Load the trained weights back into the model\n",
        "resnet50_for_gradcam.load_state_dict(torch.load('/content/drive/MyDrive/FACT LICO 13/Models/modified_resnet_90_no_mm.pth')) # DAAN I changed this, it was 'modified_resnet.pth'\n",
        "\n",
        "resnet50_for_gradcam = resnet50_for_gradcam.eval()\n",
        "\n",
        "\n",
        "# # Alternative if layers are not all the same anymore\n",
        "# # Instantiate a new standard ResNet50 model\n",
        "# standard_resnet = models.resnet50(pretrained=False).to(device)\n",
        "\n",
        "# # Get the names of the layers in the standard ResNet50\n",
        "# standard_resnet_layer_names = [name for name, _ in standard_resnet.named_children()]\n",
        "\n",
        "# # Transfer the weights from ModifiedResNet to the standard ResNet50\n",
        "# for name, module in modified_resnet.named_children():\n",
        "#     if name in standard_resnet_layer_names:\n",
        "#         # print(\"YES\")\n",
        "#         # Transfer the state dictionary of each corresponding layer\n",
        "#         getattr(standard_resnet, name).load_state_dict(module.state_dict())\n",
        "\n",
        "# # Initializing separate instance of the model fro Grad-Cam since it overlaps with the other one and causes errors with Quantitative Test\n",
        "# resnet50_for_gradcam = standard_resnet.eval()\n",
        "# resnet50_for_gradcam = resnet50_for_gradcam.to(device)\n",
        "\n",
        "\n",
        "# # Initializing the CAM extractor\n",
        "# for param in resnet50_for_gradcam.layer4.parameters():\n",
        "#     param.requires_grad = True\n",
        "\n",
        "# #COEN HZ LAYER 4 HIER DAAN Thats the last convlution layer (so where the last features are extracted)\n",
        "# cam_extractor = GradCAM(resnet50_for_gradcam, 'layer4')\n",
        "\n",
        "# gradcam_maps = []\n",
        "# original_images = []\n",
        "# outputs = []\n",
        "\n",
        "\n",
        "# # Defining the inverse transform for visualization of original image\n",
        "# inverse_transform = transforms.Compose([\n",
        "#     transforms.Normalize(mean=[0., 0., 0.], std=[1/0.229, 1/0.224, 1/0.225]),\n",
        "#     transforms.Normalize(mean=[-0.485, -0.456, -0.406], std=[1., 1., 1.]),\n",
        "#     transforms.ToPILImage(),\n",
        "# ])\n",
        "\n",
        "# for images, labels_batch in validation_loader:\n",
        "#     images.requires_grad_()   #finding the gradient w.r.t the input image\n",
        "#     images = images.to(device)\n",
        "#     for i in range(images.size(0)):\n",
        "#         # Generate Grad-CAM map\n",
        "#         with torch.enable_grad():\n",
        "#             gc_outputs = resnet50_for_gradcam(images[i].unsqueeze(0))\n",
        "#             activation_map = cam_extractor(gc_outputs.squeeze(0).argmax().item(), gc_outputs)\n",
        "\n",
        "#             # Overlay the CAM on the image\n",
        "#             gradcam_overlay = overlay_mask(to_pil_image(images[i]), to_pil_image(activation_map[0].squeeze(0), mode='F'), alpha=0.5)\n",
        "#             gradcam_overlay_np = np.array(gradcam_overlay)\n",
        "\n",
        "#             original_image = inverse_transform(images[i].cpu().detach())\n",
        "#             original_image_np = np.array(original_image.convert('RGB'))\n",
        "\n",
        "#             # print('original_image_np shape:', original_image_np.shape)\n",
        "#             # print('gradcam_overlay_np shape:', gradcam_overlay_np.shape)\n",
        "\n",
        "#             pred_class = gc_outputs.argmax(dim=1)  # Get the index of the max logit\n",
        "\n",
        "\n",
        "#             original_images.append(original_image)\n",
        "#             gradcam_maps.append(gradcam_overlay_np)\n",
        "#             img_labels = labels_batch\n",
        "#             outputs.append(pred_class)\n",
        "\n",
        "\n",
        "#         # Reset the gradients for the next image\n",
        "#         resnet50_for_gradcam.zero_grad()\n",
        "#     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ea_Pa8KqNrWi"
      },
      "outputs": [],
      "source": [
        "# for i in range(10): #currently 'subset_size' is 10 which is just used to quickly viusalize/inspect it\n",
        "#     plt.figure(figsize=(18, 6))\n",
        "\n",
        "\n",
        "\n",
        "#     # Plot original image\n",
        "#     plt.subplot(1, 3, 1)\n",
        "#     plt.imshow(original_images[i])\n",
        "#     plt.title(f'Original Image {i}, {classnames[img_labels[i]]}')\n",
        "#     plt.axis('off')\n",
        "\n",
        "#     # Plot Grad-CAM overlay\n",
        "#     plt.subplot(1, 3, 2)\n",
        "#     plt.imshow(gradcam_maps[i])\n",
        "#     plt.title(f'Grad-CAM {i}, prediction: {classnames[outputs[i]]}')\n",
        "#     plt.axis('off')\n",
        "\n",
        "#     plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ce56uRX16GOp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e73beecd-f5b5-41f0-ac55-e4e1a74518d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchray\n",
            "  Downloading torchray-1.0.0.2.tar.gz (376 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m376.2/376.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from torchray) (6.1.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from torchray) (3.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchray) (23.2)\n",
            "Requirement already satisfied: pycocotools>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchray) (2.0.7)\n",
            "Collecting pymongo (from torchray)\n",
            "  Downloading pymongo-4.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (677 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m677.1/677.1 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchray) (2.31.0)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.10/dist-packages (from torchray) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from torchray) (0.16.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pycocotools>=2.0.0->torchray) (1.23.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torchray) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torchray) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torchray) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torchray) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torchray) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torchray) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torchray) (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchray) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchray) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchray) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchray) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchray) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchray) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchray) (2.1.0)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo->torchray)\n",
            "  Downloading dnspython-2.5.0-py3-none-any.whl (305 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.4/305.4 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchray) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchray) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchray) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchray) (2023.11.17)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->torchray) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.1->torchray) (2.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.1->torchray) (1.3.0)\n",
            "Building wheels for collected packages: torchray\n",
            "  Building wheel for torchray (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchray: filename=torchray-1.0.0.2-py3-none-any.whl size=444010 sha256=2f6359fb94743a15691d1c3b1278f032aec5d540729992ee182381425ba5f3cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/89/6f/9f783db1b9c9c2f31323a990f12e156e4f99d9ae15c9a2e96c\n",
            "Successfully built torchray\n",
            "Installing collected packages: dnspython, pymongo, torchray\n",
            "Successfully installed dnspython-2.5.0 pymongo-4.6.1 torchray-1.0.0.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:05<00:00, 99.8MB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnidentifiedImageError",
          "evalue": "cannot identify image file <_io.BytesIO object at 0x78c70264e3e0>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-528d3bd78951>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Obtain example data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_example_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Grad-CAM backprop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchray/benchmark/__init__.py\u001b[0m in \u001b[0;36mget_example_data\u001b[0;34m(arch, shape)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7f/Arthur_Heyer_-_Dog_and_Cats.jpg/592px-Arthur_Heyer_-_Dog_and_Cats.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# Pre-process the image and convert into a tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3281\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3282\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cannot identify image file %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3283\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mUnidentifiedImageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x78c70264e3e0>"
          ]
        }
      ],
      "source": [
        "!pip install torchray\n",
        "from torchray.attribution.grad_cam import grad_cam\n",
        "from torchray.benchmark import get_example_data, plot_example\n",
        "\n",
        "# Obtain example data.\n",
        "_, x, category_id, _ = get_example_data()\n",
        "\n",
        "# Grad-CAM backprop.\n",
        "saliency = grad_cam(resnet50_for_gradcam, x, category_id, saliency_layer='features.29')\n",
        "\n",
        "# Plots.\n",
        "plot_example(x, saliency, 'grad-cam backprop', category_id)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y_rbhwZxAG4_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2ad01ed186cc4fbaa93783b4ca1aa7ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd04051cfaac4ab69658738abe283114",
              "IPY_MODEL_71fec566696c4fd790f206f4d46c5a60",
              "IPY_MODEL_c69a06f36c7e486a910c851d102fcdc4"
            ],
            "layout": "IPY_MODEL_3ef1fbaa833d4a82ba5b0230b0d238c8"
          }
        },
        "dd04051cfaac4ab69658738abe283114": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92e3ccae64fd427fb52f395a767df597",
            "placeholder": "​",
            "style": "IPY_MODEL_84a4e7fb595f455bae127455c28d909b",
            "value": "Downloading builder script: 100%"
          }
        },
        "71fec566696c4fd790f206f4d46c5a60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0db8673776744254a9f19110bac83e7c",
            "max": 4721,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_86a031ad1366456e95fb5c6656b54a3d",
            "value": 4721
          }
        },
        "c69a06f36c7e486a910c851d102fcdc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c155b51e49c40ab9313138a34a6314b",
            "placeholder": "​",
            "style": "IPY_MODEL_da354e528a8c475a83fbf1c967fb8632",
            "value": " 4.72k/4.72k [00:00&lt;00:00, 196kB/s]"
          }
        },
        "3ef1fbaa833d4a82ba5b0230b0d238c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92e3ccae64fd427fb52f395a767df597": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84a4e7fb595f455bae127455c28d909b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0db8673776744254a9f19110bac83e7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86a031ad1366456e95fb5c6656b54a3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c155b51e49c40ab9313138a34a6314b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da354e528a8c475a83fbf1c967fb8632": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab7d02a2ff124e6fa1b10720ace7272c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7938a373bfb4d3e8eaff8fd61c301f1",
              "IPY_MODEL_3d0c3fc847794a6385dd0c3ba627122c",
              "IPY_MODEL_222e1bf73ae74615b78bcddab75ce7bf"
            ],
            "layout": "IPY_MODEL_44ee20fff4c9478c83c62e350b49df3e"
          }
        },
        "c7938a373bfb4d3e8eaff8fd61c301f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8cb4d3aa6dd4ccf9c3e9a73940b4f4c",
            "placeholder": "​",
            "style": "IPY_MODEL_702858311e114023ae3741c0f2e24c79",
            "value": "Downloading readme: 100%"
          }
        },
        "3d0c3fc847794a6385dd0c3ba627122c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5430d8a71534436b8b50d51d101018e6",
            "max": 85424,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b36b713b0caf453eafbe011eb9f7d4d2",
            "value": 85424
          }
        },
        "222e1bf73ae74615b78bcddab75ce7bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c46fa462bc64ff487d87bf393346acf",
            "placeholder": "​",
            "style": "IPY_MODEL_d352fe7a7b604b5a8e8b23c83f16e907",
            "value": " 85.4k/85.4k [00:00&lt;00:00, 3.02MB/s]"
          }
        },
        "44ee20fff4c9478c83c62e350b49df3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8cb4d3aa6dd4ccf9c3e9a73940b4f4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "702858311e114023ae3741c0f2e24c79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5430d8a71534436b8b50d51d101018e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b36b713b0caf453eafbe011eb9f7d4d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c46fa462bc64ff487d87bf393346acf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d352fe7a7b604b5a8e8b23c83f16e907": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5b3df02fea34814bc07d985b90f5927": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a068c63109040beb8196a23a1b6179c",
              "IPY_MODEL_468d9cd1b7b744d7972b9f277358fc2d",
              "IPY_MODEL_476a7da0d8be489c89f7e76a6999cffc"
            ],
            "layout": "IPY_MODEL_0b88c58fb3ac4a22a9cb78a2fa127fcf"
          }
        },
        "5a068c63109040beb8196a23a1b6179c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_316389363eb84108a2c86a9d728182a0",
            "placeholder": "​",
            "style": "IPY_MODEL_08dfa1903d0f43d69b9371b4eee546aa",
            "value": "Downloading extra modules: 100%"
          }
        },
        "468d9cd1b7b744d7972b9f277358fc2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9acf10b627b4d81a53aafcfa8be1c62",
            "max": 46377,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d43b9048569644ee912653a99f40ea26",
            "value": 46377
          }
        },
        "476a7da0d8be489c89f7e76a6999cffc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_408fc7fc77fa4a7d8e2dbcbffd317607",
            "placeholder": "​",
            "style": "IPY_MODEL_d53a4276bde74da5a900e49f443eb8ee",
            "value": " 46.4k/46.4k [00:00&lt;00:00, 2.73MB/s]"
          }
        },
        "0b88c58fb3ac4a22a9cb78a2fa127fcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "316389363eb84108a2c86a9d728182a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08dfa1903d0f43d69b9371b4eee546aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9acf10b627b4d81a53aafcfa8be1c62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d43b9048569644ee912653a99f40ea26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "408fc7fc77fa4a7d8e2dbcbffd317607": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d53a4276bde74da5a900e49f443eb8ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6002664ed8e64a4b86fed611b033e907": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d1d2dae7b48453ead005fcb306bae7a",
              "IPY_MODEL_c2c1f306fe28498a87fa7e48be8e7434",
              "IPY_MODEL_4c97ab17e3db4a6ba7b17e9d9a6e57a8"
            ],
            "layout": "IPY_MODEL_a440fcaba5ae4ba7afc8fb93f0eb9d9a"
          }
        },
        "5d1d2dae7b48453ead005fcb306bae7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9ad82f96b0c491e8c5f4d103b7dc110",
            "placeholder": "​",
            "style": "IPY_MODEL_300b45f5b947416d8559e6c1900c5878",
            "value": "100%"
          }
        },
        "c2c1f306fe28498a87fa7e48be8e7434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7e86d83d0a44ce39b9ec92d6eb45559",
            "max": 32,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3d53a7ea393427db92e08b42ccc21db",
            "value": 32
          }
        },
        "4c97ab17e3db4a6ba7b17e9d9a6e57a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e0143fe6f8a4cd0ba46281c64e3b5ef",
            "placeholder": "​",
            "style": "IPY_MODEL_b56d48aba49b4c5c8885f33cf1b6616a",
            "value": " 32/32 [00:06&lt;00:00,  5.70it/s]"
          }
        },
        "a440fcaba5ae4ba7afc8fb93f0eb9d9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9ad82f96b0c491e8c5f4d103b7dc110": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "300b45f5b947416d8559e6c1900c5878": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7e86d83d0a44ce39b9ec92d6eb45559": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3d53a7ea393427db92e08b42ccc21db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e0143fe6f8a4cd0ba46281c64e3b5ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b56d48aba49b4c5c8885f33cf1b6616a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd6a936f455446f18cbe2926652b8ba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c1b2c652a1cd4c75bf5b061b09e0eb59",
              "IPY_MODEL_62495dffef8c46ba9c4f4b4b80d31458",
              "IPY_MODEL_4526f6df79fe469a8718958bd72c1ef1"
            ],
            "layout": "IPY_MODEL_e2a86ae4fde9453dbee600c36e961f38"
          }
        },
        "c1b2c652a1cd4c75bf5b061b09e0eb59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d341a7319eb466794e61bd77d0f75c9",
            "placeholder": "​",
            "style": "IPY_MODEL_88eec725c61d46b4967cd74f21f1e28c",
            "value": "100%"
          }
        },
        "62495dffef8c46ba9c4f4b4b80d31458": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_356bf7cc18594cc4a34fc15fbcd0184e",
            "max": 32,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ffa8dd72f0414ef2a3eac5c1c9c8f2d9",
            "value": 32
          }
        },
        "4526f6df79fe469a8718958bd72c1ef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a4a891edd0f43759dbca48297fa8a2b",
            "placeholder": "​",
            "style": "IPY_MODEL_ec826a48f39d406abc0f426631203de9",
            "value": " 32/32 [00:19&lt;00:00,  1.81it/s]"
          }
        },
        "e2a86ae4fde9453dbee600c36e961f38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d341a7319eb466794e61bd77d0f75c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88eec725c61d46b4967cd74f21f1e28c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "356bf7cc18594cc4a34fc15fbcd0184e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffa8dd72f0414ef2a3eac5c1c9c8f2d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a4a891edd0f43759dbca48297fa8a2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec826a48f39d406abc0f426631203de9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c299a53508bd4c9abdc5951b5f763a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e53743c092c40e59c65630a25f6c643",
              "IPY_MODEL_ee98613527e54752925e632daf2d74c8",
              "IPY_MODEL_b1bd568bd470403fa588cbfdc586c85f"
            ],
            "layout": "IPY_MODEL_864ed169b90f42be8adcae5c15de85b6"
          }
        },
        "0e53743c092c40e59c65630a25f6c643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a86a4661fa8f4bd8b90de0d37529fa04",
            "placeholder": "​",
            "style": "IPY_MODEL_4bce7da4069e4ddd97f128162f417c9a",
            "value": "100%"
          }
        },
        "ee98613527e54752925e632daf2d74c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce2e66cb53a94658bf2edc21beee0104",
            "max": 32,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a535e41bb9ed4914bebff6b3070dcf5b",
            "value": 32
          }
        },
        "b1bd568bd470403fa588cbfdc586c85f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ee673d300e34c75820cd9f87e72c52c",
            "placeholder": "​",
            "style": "IPY_MODEL_76e47bacf3a4424ca20404ace441dc85",
            "value": " 32/32 [00:06&lt;00:00,  5.09it/s]"
          }
        },
        "864ed169b90f42be8adcae5c15de85b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a86a4661fa8f4bd8b90de0d37529fa04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bce7da4069e4ddd97f128162f417c9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce2e66cb53a94658bf2edc21beee0104": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a535e41bb9ed4914bebff6b3070dcf5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ee673d300e34c75820cd9f87e72c52c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76e47bacf3a4424ca20404ace441dc85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d10e29182e554d6b9e15650f6a4a3d28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6fcf8f55478b469cb1dc8cb044531ac1",
              "IPY_MODEL_cd695ce38f3e455b81473dc1c752397b",
              "IPY_MODEL_4c10646d9d8a44bda418c591eed6cbce"
            ],
            "layout": "IPY_MODEL_5846d4a3bc194fc299cdb240597d49b5"
          }
        },
        "6fcf8f55478b469cb1dc8cb044531ac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b83cd386524f45258e193dbf7d781e58",
            "placeholder": "​",
            "style": "IPY_MODEL_81937a9cf50d40e28b8e3c9d186fec10",
            "value": " 69%"
          }
        },
        "cd695ce38f3e455b81473dc1c752397b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cec563f423134f4e95d6da1f138acee1",
            "max": 32,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c64c90bc2cb4101b23a95581f5b8adc",
            "value": 22
          }
        },
        "4c10646d9d8a44bda418c591eed6cbce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc16663948ca445fb01f400f168b4ada",
            "placeholder": "​",
            "style": "IPY_MODEL_4aca5460752249e69a73a3e575a463e0",
            "value": " 22/32 [00:13&lt;00:06,  1.65it/s]"
          }
        },
        "5846d4a3bc194fc299cdb240597d49b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b83cd386524f45258e193dbf7d781e58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81937a9cf50d40e28b8e3c9d186fec10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cec563f423134f4e95d6da1f138acee1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c64c90bc2cb4101b23a95581f5b8adc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc16663948ca445fb01f400f168b4ada": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4aca5460752249e69a73a3e575a463e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}